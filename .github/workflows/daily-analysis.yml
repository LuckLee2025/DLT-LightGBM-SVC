name: Daletou Data and Analysis

on:
  schedule:
    # UTC时间周日、周二、周五的 22:00，对应北京时间周一、周三、周六的 6:00
    - cron: '0 22 * * 0,2,5'
  workflow_dispatch:

jobs:
  daily_process:
    runs-on: ubuntu-latest
    env:
      TZ: Asia/Shanghai # Set timezone for consistent date/time operations

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0 # Fetch all history for git operations
        # token: ${{ secrets.PAT_FOR_CHECKOUT_AND_PUSH }} # Optional: If GITHUB_TOKEN has permission issues for subsequent pushes or certain repo setups. Usually GITHUB_TOKEN is fine.

    - name: Set up Python 3.9
      uses: actions/setup-python@v5
      with:
        python-version: 3.9

    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run data acquisition script
      run: python dlt_data_processor.py

    - name: Run bonus calculation script
      run: python dlt_bonus_calculation.py
      
    - name: Run analysis script
      run: python dlt_analyzer.py

    - name: Create fixed filename copy of latest analysis report
      run: |
        set -e
        latest_report_file=$(find . -maxdepth 1 -name 'dlt_analysis_output_*.txt' -print0 | xargs -0 ls -1 | sort -r | head -n 1)
        if [ -n "$latest_report_file" ] && [ -f "$latest_report_file" ]; then
          cp "$latest_report_file" "latest_dlt_analysis.txt"
          echo "Created fixed filename copy: latest_dlt_analysis.txt from $latest_report_file"
        else
          echo "No dlt_analysis_output_*.txt files found, or latest_report_file variable is empty. Skipping copy."
        fi

    - name: Clean old reports - keep only latest 3
      run: |
        set -e
        echo "--- Cleaning old analysis reports ---"
        mapfile -t reports < <(find . -maxdepth 1 -name 'dlt_analysis_output_*.txt' -print0 | xargs -0 ls -1 | sort)
        count=${#reports[@]}
        keep=3
        echo "Found $count reports. Configured to keep $keep latest."
        if [ "$count" -gt "$keep" ]; then
          num_to_delete=$((count - keep))
          echo "Deleting $num_to_delete oldest reports:"
          for i in $(seq 0 $((num_to_delete - 1))); do
            report_to_delete="${reports[$i]}"
            if [ -f "$report_to_delete" ]; then
              echo "Removing: $report_to_delete"
              rm "$report_to_delete"
            else
              echo "Skipping (not found): $report_to_delete"
            fi
          done
        else
          echo "No cleanup needed. $count report(s) found (≤ $keep)."
        fi
        echo "Listing remaining analysis reports:"
        find . -maxdepth 1 -name 'dlt_analysis_output_*.txt' | sort
        echo "--- Finished cleaning reports ---"

    - name: Configure Git
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"

    - name: Commit updated files
      run: |
        set -e
        echo "--- Staging and Committing Files ---"
        git add -u
        files_to_commit=(
          "daletou.csv"
          "latest_dlt_analysis.txt"
          "latest_dlt_calculation.txt"
          "weights_config.json"
        )
        for file_path in "${files_to_commit[@]}"; do
          if [ -f "$file_path" ]; then
            git add "$file_path"
            echo "Staged: $file_path"
          else
            echo "Skipping (not found): $file_path"
          fi
        done
        find . -maxdepth 1 -name 'dlt_analysis_output_*.txt' -print0 | xargs -0 -r git add -f
        echo "Staged any new dlt_analysis_output_*.txt files."
        echo "Current git status:"
        git status --porcelain
        if git diff --staged --quiet; then
          echo "No changes to commit."
        else
          git commit -m "Auto update: Data and Analysis results $(date +'%Y-%m-%d %H:%M:%S %Z')"
          echo "Changes committed."
        fi
        echo "--- Finished Staging and Committing ---"

    - name: Pull remote changes to sync before push
      run: |
        echo "Current branch: $(git rev-parse --abbrev-ref HEAD)"
        echo "Target branch from GITHUB_REF_NAME: ${{ github.ref_name }}"
        # Set pull strategy to merge (default, but explicit) or rebase
        # For automated processes, merge is often safer if conflicts are unlikely
        # or if a merge commit is acceptable.
        git config pull.rebase false # Use 'true' for rebase, 'false' for merge
        
        # Pull changes from the remote branch.
        # This will attempt to merge remote changes. If there are conflicts
        # that Git cannot auto-resolve, this step will fail, and the workflow will stop.
        # Using --no-edit to avoid an editor opening for the merge commit message.
        git pull origin ${{ github.ref_name }} --no-edit
        echo "Successfully pulled and merged remote changes (if any)."
      # Optional: Add retry logic or specific conflict handling if needed,
      # but generally, failing on conflict is the safest default for CI.

    - name: Push changes
      uses: ad-m/github-push-action@v0.8.0
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        # Use github.ref_name to get the short branch name (e.g., "main")
        # This is generally more robust for git commands than the full github.ref (e.g., "refs/heads/main")
        branch: ${{ github.ref_name }}
        # force: false # Default. Do not force push unless you absolutely need to and understand the consequences.
